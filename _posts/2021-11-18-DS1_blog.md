---
toc: false 
layout: post
description: Anurendra Kumar (ak32@illinois.edu) https://anurendra.github.io/
categories: [DS, Physics+ML]
title: DS1 Discovering Equations

---

<div class="stackedit__html"><hr>
<h3 id="abstract">Abstract</h3>
<p>Today we’ll talk about on how we  can use compressive sensive and optimization to learn the dynamics of an underlying physical system. This blog is based on the paper from Prof. Kutz’s lab - <a href="https://www.pnas.org/content/113/15/3932">Discovering governing equations from data by sparse<br>
identification of nonlinear dynamical systems</a>. The paper develops a dictionary learning framework with overrepresented dictionary which enables us for interpretable non-linearity. We’ll discuss about it in the details below.</p>
<hr>
<h3 id="history--modeling-dynamics-from-data">History : Modeling Dynamics from Data</h3>
<p>Science started from astronomy, which started by observing the movements of stars, planets and heavenly bodies. Copernicus presented heliocentric theory which proposed sun as the center of the universe instead of earth. Later, Kepler gathered huge amount of planetary motion data. This enabled him to come up with three Kepler’s laws,</p>
<p><img src="https://www.super-science-fair-projects.com/wp-content/uploads/2009/10/keplers-laws.png" alt=""></p>
<p>Finally, Newton developed a unified theory of motion across the universe. While Kepler’s contribution was primarily in generating detailed data, Newton’s contribution was in developing a unified theory which explains data.</p>
<h3 id="background-symbolic-regression-and-compressive-sensing">Background: Symbolic Regression and Compressive Sensing</h3>
<p>Symbolic regression which is a generalization of regression, aims to learn the underlying interaction in data. It searches over the space of all possible mathematical formulas which best predict the output variable, starting from a set of base functions like addition, trigonometric functions, and exponentials. However, it is computationally expensive, does not clearly scale well to large-scale dynamical systems of interest, and may be prone to over-fitting.</p>
<p><img src="https://www.researchgate.net/profile/Michael-Affenzeller/publication/317026414/figure/fig2/AS:621592413499392@1525210588090/Symbolic-regression-model-in-mathematical-notation-as-well-as-in-syntax-tree.png" alt=""></p>
<p>This paper utilizes ideas from sparse regression which has been used to find solutions for underdetermined linear systems. Sparsity helps us break the Nyquist–Shannon sampling theorem. In sparse regression, signal <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathnormal">x</span></span></span></span></span> is K sparse,<br>
<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mi mathvariant="normal">Ψ</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">x = \Psi s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord">Ψ</span><span class="mord mathnormal">s</span></span></span></span></span><br>
<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">l1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathnormal" style="margin-right: 0.01968em;">l</span><span class="mord">1</span></span></span></span></span> norm is often imposed as regularization for sparsity. Extensive research in this area has been done often referred as Compressive Sensing. Terrence Tao, who is a professor at UCLA actively works on this. Their methods bypasees our need to perform a combinatorially intractable bruteforce search for sparse solution. It is found with<br>
high probability using convex methods that scale to large problems.</p>
<h3 id="problem-set-up-dynamical-systems">Problem Set up: Dynamical Systems</h3>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>d</mi><mrow><mi>d</mi><mi>t</mi></mrow></mfrac><mi mathvariant="bold">x</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{d}{dt}\mathbf{x}(t) = f(\mathbf{x}(t))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.22511em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.880108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">t</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathbf">x</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord mathbf">x</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">))</span></span></span></span></span><br>
Let’s assume  <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{x}(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathbf">x</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></span>  denotes state at time <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.61508em; vertical-align: 0em;"></span><span class="mord mathnormal">t</span></span></span></span></span>, <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathnormal" style="margin-right: 0.10764em;">f</span></span></span></span></span> denotes with  dynamics f(\mathbf{x}(t).  In most physical systems,  only a few nonlinear terms in the<br>
dynamics exist. Therefore it’s sparse in a high-dimensional nonlinear function space. So, if we can perform non-linear transformation, we can cast problem of identification of dynamical system as sparse regresssion.</p>
<h3 id="dynamical-systems-as-sparse-regression">Dynamical Systems as Sparse Regression</h3>
<p>Let’s denote <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68611em; vertical-align: 0em;"></span><span class="mord mathbf">X</span></span></span></span></span> and   <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi mathvariant="bold">X</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot{\mathbf{X}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92297em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92297em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathbf">X</span></span><span class="" style="top: -3.25511em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.05555em;"><span class="mord">˙</span></span></span></span></span></span></span></span></span></span></span> as state and dynamic matrix. <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathnormal" style="margin-right: 0.03148em;">k</span></span></span></span></span> -th row of <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68611em; vertical-align: 0em;"></span><span class="mord mathbf">X</span></span></span></span></span> contains observation vector at time <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathnormal" style="margin-right: 0.03148em;">k</span></span></span></span></span>. Now, let’s do many transformation of <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68611em; vertical-align: 0em;"></span><span class="mord mathbf">X</span></span></span></span></span> , such as linear, polynomial, cosine and exponentials. This should be guided by the applications where the possible non-linearities is known. Finally we append these matrices to contain a big matrix <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord">Θ</span></span></span></span></span>.  Then we can solve the following problem,<br>
<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi mathvariant="bold">X</mi><mo>˙</mo></mover><mo>=</mo><mi mathvariant="normal">Θ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\dot{\mathbf{X}} =\Theta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92297em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92297em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathbf">X</span></span><span class="" style="top: -3.25511em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.05555em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord">Θ</span><span class="mord mathnormal" style="margin-right: 0.13889em;">W</span></span></span></span></span><br>
where, weight <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathnormal" style="margin-right: 0.13889em;">W</span></span></span></span></span> has sparse coefficients. It can be seen that each row has separate optimization. Therefore, complexity increaseslinearly with the number of time instants and not on the number of non-linear transformations. Basis functions are really important here.  So we should test many different function bases and use the sparsity and accuracy of the resulting model as a diagnostic tool to determine the correct basis to represent the dynamics.</p>
<h3 id="approximating-derivatives">Approximating Derivatives</h3>
<p>In reality we only observe discrete values of <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68611em; vertical-align: 0em;"></span><span class="mord mathbf">X</span></span></span></span></span> and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi mathvariant="bold">X</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot{\mathbf{X}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92297em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92297em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathbf">X</span></span><span class="" style="top: -3.25511em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.05555em;"><span class="mord">˙</span></span></span></span></span></span></span></span></span></span></span> is not known. Therefore, we need to approximate it.  Total variation  regularization is used to denoise derivative. To counter the noise due to approximation, we should rather solve the following problem,<br>
<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi mathvariant="bold">X</mi><mo>˙</mo></mover><mo>=</mo><mi mathvariant="normal">Θ</mi><mi>W</mi><mo>+</mo><mi>σ</mi><mi>Z</mi></mrow><annotation encoding="application/x-tex">\dot{\mathbf{X}} = \Theta W + \sigma Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92297em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92297em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathbf">X</span></span><span class="" style="top: -3.25511em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.05555em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.76666em; vertical-align: -0.08333em;"></span><span class="mord">Θ</span><span class="mord mathnormal" style="margin-right: 0.13889em;">W</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathnormal" style="margin-right: 0.03588em;">σ</span><span class="mord mathnormal" style="margin-right: 0.07153em;">Z</span></span></span></span></span><br>
where, <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathnormal" style="margin-right: 0.07153em;">Z</span></span></span></span></span> is iid and normally distributed. Traditionally, people use Lasso for sparse regression.  However, it is computationally expensive. The paper uses Sequential thresholded least-squares algorithm to find it.  Depending on the noise, it may be necessary to filter <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68611em; vertical-align: 0em;"></span><span class="mord mathbf">X</span></span></span></span></span> and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi mathvariant="bold">X</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot{\mathbf{X}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.92297em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.92297em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathbf">X</span></span><span class="" style="top: -3.25511em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.05555em;"><span class="mord">˙</span></span></span></span></span></span></span></span></span></span></span>.</p>
<h3 id="dynamical-systems-with-pde">Dynamical Systems with PDE</h3>
<p>Most of the physical systems are PDE and not ODE. This method poses a serious problem since numerical discretization on a spatial grid is exponentially large. For example, in fluid Dynamics, a simple 2D and 3D flows may require tens of thousands up to billions of variables to represent the discretized system. Therefore, current formulation is ill suited, since each row has separate optimization.</p>
<p>However, the good news that many high-dimensional systems of interest evolve on a low dimensional manifold or attractor that is well-approximated using a low-rank basis. Therefore, we can first  use SVD to decompose <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68611em; vertical-align: 0em;"></span><span class="mord mathbf">X</span></span></span></span></span>. This has attracted decades of research for fluid dymaics. Proper orthogonal decomposition is a state of the art method for decomposing the flow governed by the Navier stokes formulation.</p>
<h3 id="results-lorenz-system">Results: Lorenz System</h3>
<p><img src="https://www.pnas.org/content/113/15/3932/F1.large.jpg" alt=""></p>
<p>The paper shows that proposed method can identify lorenz attractor.  It can capture rich and chaotic dynamics that evolve on an attractor. Only a few terms in the right-hand side of the equation are required</p>
<h3 id="results-fluid-dynamics">Results: Fluid Dynamics</h3>
<p><img src="https://www.pnas.org/content/pnas/113/15/3932/F2.large.jpg" alt=""></p>
<p>The paper simulates fluid flow data, Data are collected for the fluid flow past a cylinder using direct numerical simulations of the 2D Navier–Stokes equations. It then transforms to a lower dimension and perform sparse regression.  We can see that it is able to identify dynamics.</p>
<h3 id="extensions">Extensions</h3>
<p>There can be a scenario where dynamics is also dependent on other parameters. In these scenario, we can solve,<br>
<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>μ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\dot{x} = f(x,\mu)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.66786em; vertical-align: 0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.66786em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.11111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span></span></p>
<h3 id="references">References</h3>
<p>Brunton, S. L., Proctor, J. L., &amp; Kutz, J. N. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. <em>Proceedings of the national academy of sciences</em>, <em>113</em>(15), 3932-3937.</p>
</div>
